{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('crx.data',index_col=None) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Svm_separating_hyperplanes_%28SVG%29.svg/512px-Svm_separating_hyperplanes_%28SVG%29.svg.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$g(x) = w_0 + w_1x_1 + w_2x_2 = \\langle w, x \\rangle =  w^\\top x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(w) = \\sum_i [y^{(i)} \\langle w, x^{(i)} \\rangle < 0] \\rightarrow \\min_w$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://jaquesgrobler.github.io/Online-Scikit-Learn-stat-tut/_images/plot_sgd_loss_functions_11.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знакомьтесь - Перцептрон!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это самая простая модель человеческой нейронной сети. В ней есть входы, которые взвешиваются и суммируются. Затем взвешенная сумма проходит через некую функцию активации (в данном случае $sign(\\cdot)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://blog.dbrgn.ch/images/2013/3/26/perceptron.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перцептрон можно использовать для классификации. <br/>\n",
    "Существует итерационный алгоритм, который корректирует веса $w_0 \\cdots w_n$ до тех пор, пока ошибки имею место быть:\n",
    " \n",
    "```python\n",
    "Randomly initialize weights: w=(w_0, \\dots, w_d)\n",
    "Until no errors on train set:\n",
    "    for i in xrange(N):\n",
    "    if y_i * w.T * x_i  < 0:\n",
    "        w = w + alpha * y_i * x_i\n",
    "```\n",
    "Этот алгоритм гарантированно сходится для линейно разделимой выборки.\n",
    "А если это не наш случай?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знакомьтесь - Логистическая регрессия!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как мы начнем, рассмотрим функцию $$\\sigma(z) = \\frac{1}{1 + exp{(-z)}},$$она называется **сигмойда**. Постройте данную фукнцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно несколькими способами представить линейную регрессию. Один из самых простых - вот какой.\n",
    "\n",
    "Рассмотрим принадлежность к классу $y=\\pm1$ некого объекта $x$: $p(y=\\pm1 | x,w)$ и выразим её через **сигмойду** от **отступа**:\n",
    "$$p(y=\\pm1|x,w) = \\sigma(y \\langle w, x \\rangle) $$\n",
    "\n",
    "Будем максимизировать правдоподобие $$\\mathcal{L}(w) = \\prod_i p(y^{(i)}|x^{(i)},w) \\rightarrow \\max_w$$\n",
    "Возьмем от этого логарифм и поставим минус - получится минимизация логарифмической функции потерь:\n",
    "\n",
    "$$L(w) = -\\sum_i \\log(\\sigma(y^{(i)} \\langle w, x^{(i)} \\rangle)) \\rightarrow \\min_w$$\n",
    "\n",
    "Посчитаем градиент этой функции потерь по $w$:\n",
    "\n",
    "$$ \\frac{\\partial L(w)}{\\partial w} = \\dots$$\n",
    "\n",
    "**История с градиентным спуском, регуляризацией, мультиколлинеарностью и шкалированием признаков здесь полностью повторяется!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем выборку и применим к ней линейную регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = np.r_[np.random.randn(20, 2) + [2, 2],\n",
    "          np.random.randn(20, 2) + [-2, -2]]\n",
    "y = [-1] * 20 + [1] * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(X[:, 0],\n",
    "           X[:, 1],\n",
    "           c=y,\n",
    "           cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите LogisticRegression() на данных `X` и `y`, изобразите разделяющую прямую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "## Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
