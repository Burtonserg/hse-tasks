{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронные сети\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала обучим обычную полносвязную нейронную сеть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images_separately(images):\n",
    "    \"Plot the six MNIST images separately.\"\n",
    "    fig = plt.figure()\n",
    "    for j in range(1, 7):\n",
    "        ax = fig.add_subplot(1, 6, j)\n",
    "        ax.matshow(np.reshape(images[j-1], (28, 28)), cmap = matplotlib.cm.binary)\n",
    "        plt.xticks(np.array([]))\n",
    "        plt.yticks(np.array([]))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABFCAYAAAB9nJwHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBxuc4FLOgqpcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27ca3f3e400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "plot_images_separately(mnist.train.images)\n",
    "print(mnist.train.labels[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Единицы соответствуют индексу класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Однослойная нейронная сеть\n",
    "\n",
    "Построим модель в tensorflow. Tensorflow - это графический фраемворк, предназначенный в первую очередь для работы с нейронными сетями. На самом деле Вы можете создавать здесь любые алгоритмы машинного обучения. Основная идея работы с tensorflow - вы описываете порядок, в котором создаются переменные и выполняются операции, после чего запускаете обсчёт всего графа. \n",
    "\n",
    "В примере ниже мы создаем простейщую модель: \n",
    "$y = \\mbox{softmax}(Wx + b)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MacOS:\n",
    "* sudo easy_install pip\n",
    "* sudo easy_install --upgrade six\n",
    "* export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0-py3-none-any.whl\n",
    "* sudo pip3 install --upgrade $TF_BINARY_URL\n",
    "\n",
    "Windows:\n",
    "* Install docker - https://download.docker.com/win/stable/InstallDocker.msi\n",
    "* Download container - docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784]) \n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(x, W) + b\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что в tensorflow существует два вида перменных. \n",
    "tf.placeholder - переменные, значения которых подаются из вне. \n",
    "tf.Variable - переменные, которые как-то определяются внутри графа и могут зависеть от внешних переменных. Только tf.Variable могут быть обучаемыми переменными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Variable:0' shape=(784, 10) dtype=float32_ref>\", \"<tf.Variable 'Variable_1:0' shape=(10,) dtype=float32_ref>\"] and loss Tensor(\"Mean:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0df4d312a7e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcross_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[0;32m    320\u001b[0m           \u001b[1;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m           \u001b[1;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Variable:0' shape=(784, 10) dtype=float32_ref>\", \"<tf.Variable 'Variable_1:0' shape=(10,) dtype=float32_ref>\"] and loss Tensor(\"Mean:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sanek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_entropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-320a78d6c790>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%d iter, cost %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_entropy' is not defined"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "  # Train\n",
    "tf.initialize_all_variables().run()\n",
    "for i in range(5000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    cost, _ = sess.run([cross_entropy, train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    if (i % 100 == 0):\n",
    "        print(\"%d iter, cost %f\" % (i, cost))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9233\n"
     ]
    }
   ],
   "source": [
    "# Test trained model\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                      y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нейронная сеть с двумя полносвязными слоями\n",
    "\n",
    "Попробуем добавить промежуточный полносвязный слой. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.placeholder(tf.float32, [None, 784]) \n",
    "\n",
    "W1 = tf.Variable(tf.zeros([784, 100]))\n",
    "b1 = tf.Variable(tf.zeros([100]))\n",
    "W2 = tf.Variable(tf.zeros([100, 10]))\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "x2 = tf.sigmoid(tf.matmul(x1, W1) + b1)\n",
    "y = tf.nn.softmax(tf.matmul(x2, W2) + b2)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f85785be940>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/archy/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 522, in __del__\n",
      "    self.close()\n",
      "  File \"/home/archy/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1262, in close\n",
      "    self._default_session.__exit__(None, None, None)\n",
      "  File \"/home/archy/anaconda3/lib/python3.5/contextlib.py\", line 66, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/home/archy/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3536, in get_controller\n",
      "    % type(default))\n",
      "AssertionError: Nesting violated for default stack of <class 'weakref'> objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iter, cost 2.302585\n",
      "100 iter, cost 2.277459\n",
      "200 iter, cost 2.040760\n",
      "300 iter, cost 1.841977\n",
      "400 iter, cost 1.813944\n",
      "500 iter, cost 1.668663\n",
      "600 iter, cost 1.421710\n",
      "700 iter, cost 1.181906\n",
      "800 iter, cost 0.716482\n",
      "900 iter, cost 0.782747\n",
      "1000 iter, cost 0.435634\n",
      "1100 iter, cost 0.428862\n",
      "1200 iter, cost 0.456217\n",
      "1300 iter, cost 0.366845\n",
      "1400 iter, cost 0.249427\n",
      "1500 iter, cost 0.361976\n",
      "1600 iter, cost 0.430709\n",
      "1700 iter, cost 0.265916\n",
      "1800 iter, cost 0.260610\n",
      "1900 iter, cost 0.184914\n",
      "2000 iter, cost 0.264893\n",
      "2100 iter, cost 0.292694\n",
      "2200 iter, cost 0.377455\n",
      "2300 iter, cost 0.214893\n",
      "2400 iter, cost 0.153792\n",
      "2500 iter, cost 0.242292\n",
      "2600 iter, cost 0.542443\n",
      "2700 iter, cost 0.348029\n",
      "2800 iter, cost 0.189372\n",
      "2900 iter, cost 0.150312\n",
      "3000 iter, cost 0.235022\n",
      "3100 iter, cost 0.277755\n",
      "3200 iter, cost 0.338690\n",
      "3300 iter, cost 0.187746\n",
      "3400 iter, cost 0.402864\n",
      "3500 iter, cost 0.227085\n",
      "3600 iter, cost 0.344348\n",
      "3700 iter, cost 0.406425\n",
      "3800 iter, cost 0.141283\n",
      "3900 iter, cost 0.210679\n",
      "4000 iter, cost 0.355419\n",
      "4100 iter, cost 0.458511\n",
      "4200 iter, cost 0.161388\n",
      "4300 iter, cost 0.248154\n",
      "4400 iter, cost 0.207242\n",
      "4500 iter, cost 0.163295\n",
      "4600 iter, cost 0.182078\n",
      "4700 iter, cost 0.259725\n",
      "4800 iter, cost 0.303692\n",
      "4900 iter, cost 0.355110\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "  # Train\n",
    "tf.initialize_all_variables().run()\n",
    "for i in range(5000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    cost, _ = sess.run([cross_entropy, train_step], feed_dict={x1: batch_xs, y_: batch_ys})\n",
    "    if (i % 100 == 0):\n",
    "        print(\"%d iter, cost %f\" % (i, cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9224\n"
     ]
    }
   ],
   "source": [
    "# Test trained model\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x1: mnist.test.images,\n",
    "                                      y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution:\n",
    "<img src=\"3.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max pooling:\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "# первый слой\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#второй слой\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#полносвязный слой\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
