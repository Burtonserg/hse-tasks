{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### пункт 0\n",
    "\n",
    "Загрузите датасет с помощью функции fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = fetch_20newsgroups(remove=('headers', 'footer', 'quotes')).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 1: LDA из sklearn\n",
    "\n",
    "- Однопоточный, неэффективный.\n",
    "- Совместим в векторайзерами sklearn\n",
    "- легко исопльзовать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### пункт 1\n",
    "\n",
    "1) создайте объект класса CountVectorizer \n",
    "\n",
    "2) примените его к вашей коллекции, причем так, чтобы коллекция документов была представлена не всеми словами из словаря, а только 1000 словами, которые наиболее часто встречаются в коллекции\n",
    "\n",
    "(для этого надо воспользоваться методом fit_transform и указать соответствующий параметр)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "transformed_dataset = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### пункт 2\n",
    "Получите названия тех топ-1000 слов, которые вы только что закодировали векторайзером"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_feature_names = \n",
    "assert len(tf_feature_names) == 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите LatentDirichletAllocation из sklearn со следующими параметрами n_topics=20, max_iter=50, learning_method='batch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуйтесь следующей функцией, чтобы вывести ключевые слова конкретной темы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print 'Topic {}:'.format(topic_idx)\n",
    "        print ' '.join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 10\n",
    "print_top_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2: Gensim\n",
    "\n",
    "- Неэффективный.\n",
    "- Совместим в векторайзерами sklearn.\n",
    "- Легко использовать.\n",
    "- Поддерживает несколько входных форматов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте корпус следующим образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "corpus = gensim.matutils.Sparse2Corpus(transformed_dataset,documents_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### пункт 3\n",
    "Заполните словарь id2word в виде {индекс:слово}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### пункт 4\n",
    "Обучите модель LDA из gensim (для этого надо воспользоваться gensim.models.ldamodel.LdaModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите наиболее вероятные слова для каждой темы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda.print_topics(lda.num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### пункт 5\n",
    "Обучите модель LSI из gensim (для этого надо воспользоваться gensim.models.lsimodel.LsiModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите наиболее вероятные слова для каждой темы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.print_topics(lsi.num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какая модель по вашему мнению лучше выделила темы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
